# Air Quality Data Pipeline

**ETL pipeline w Pythonie na Google Cloud Platform.**  
Pobieranie danych jakoÅ›ci powietrza z OpenAQ API, walidacja i zapis CSV do bucketu Google Cloud Storage.  
Uruchamiane w Google Cloud Functions, z opcjÄ… harmonogramu (Cloud Scheduler + Pub/Sub).

---

## ğŸ›  Stack technologiczny
- **Python 3.10** â€“ implementacja logiki ETL  
- **Requests** â€“ pobieranie danych z API OpenAQ  
- **Google Cloud Functions** â€“ uruchamianie skryptu ETL  
- **Google Cloud Storage (GCS)** â€“ przechowywanie plikÃ³w wynikowych (CSV)  
- **Cloud Scheduler + Pub/Sub** â€“ (opcjonalnie) cykliczne uruchamianie ETL  
- **Cloud Logging** â€“ monitorowanie logÃ³w i bÅ‚Ä™dÃ³w dziaÅ‚ania funkcji  

---

## âœ¨ FunkcjonalnoÅ›ci
- Pobiera dane o jakoÅ›ci powietrza z OpenAQ API  
- Filtruje tylko **aktywne stacje pomiarowe** (dane z ostatnich 30 dni)  
- Zbiera dane z **min. 3 stacji** dla Warszawy i Nowego Jorku  
- Waliduje poprawnoÅ›Ä‡ wartoÅ›ci (tylko liczbowe wartoÅ›ci)  
- Automatycznie wysyÅ‚a plik CSV do wskazanego bucketu GCS  
- MoÅ¼e byÄ‡ uruchamiany manualnie (**HTTP trigger**) lub cyklicznie (**Cloud Scheduler + Pub/Sub**)  

---

## ğŸ“‚ Struktura projektu
```bash
.
â”œâ”€â”€ main.py           # Kod ÅºrÃ³dÅ‚owy funkcji ETL
â”œâ”€â”€ requirements.txt  # Lista zaleÅ¼noÅ›ci Pythona
â””â”€â”€ README.md         # Dokumentacja
âš™ï¸ Wymagania
Aktywny projekt w Google Cloud Platform

Uprawnienia do tworzenia Cloud Functions, uÅ¼ywania GCS i Cloud Scheduler

Python 3.10+

Klucz API do OpenAQ (ustawiany jako zmienna Å›rodowiskowa OPENAQ_API_KEY)

ğŸš€ Deploy funkcji do Google Cloud Functions
1. Utworzenie bucketu (jeÅ›li nie istnieje)
bash
Skopiuj kod
gsutil mb -l europe-central2 gs://NAZWA_TWOJEGO_BUCKETU
2. Deploy funkcji
bash
Skopiuj kod
gcloud functions deploy openaq_etl \
  --runtime python310 \
  --trigger-http \
  --allow-unauthenticated \
  --entry-point openaq_etl \
  --region=europe-central2 \
  --project=NAZWA_TWOJEGO_PROJEKTU \
  --set-env-vars OPENAQ_API_KEY=TWÃ“J_API_KEY
ğŸ§ª Testowanie rÄ™czne
Po deployu, funkcja dostÄ™pna jest pod publicznym URL-em:

bash
Skopiuj kod
https://europe-central2-NAZWA_TWOJEGO_PROJEKTU.cloudfunctions.net/openaq_etl
WywoÅ‚anie endpointu zwrÃ³ci komunikat o sukcesie i zapisze plik CSV do wskazanego bucketu GCS.

â± Automatyzacja â€“ Cloud Scheduler
1. UtwÃ³rz temat Pub/Sub
bash
Skopiuj kod
gcloud pubsub topics create openaq-trigger
2. Podepnij funkcjÄ™ do Pub/Sub (zamiast HTTP)
bash
Skopiuj kod
gcloud functions deploy openaq_etl \
  --runtime python310 \
  --trigger-topic=openaq-trigger \
  --entry-point openaq_etl \
  --region=europe-central2 \
  --project=NAZWA_TWOJEGO_PROJEKTU \
  --set-env-vars OPENAQ_API_KEY=TWÃ“J_API_KEY
3. UtwÃ³rz zadanie w Cloud Scheduler
bash
Skopiuj kod
gcloud scheduler jobs create pubsub openaq-job \
  --schedule="0 7 * * *" \
  --topic=openaq-trigger \
  --message-body="Start ETL" \
  --location=europe-central2
Cron 0 7 * * * oznacza codziennie o 7:00 UTC.
MoÅ¼esz dostosowaÄ‡ harmonogram wedÅ‚ug potrzeb (cron syntax).

ğŸ“Š Monitoring
Cloud Logging â€“ wszystkie logi trafiajÄ… do Stackdriver (Google Cloud Logging)

Cloud Storage â€“ sprawdzaj bucket NAZWA_TWOJEGO_BUCKETU, czy pojawiajÄ… siÄ™ pliki CSV

Cloud Scheduler â€“ w panelu widoczne sÄ… ostatnie wykonania i ewentualne bÅ‚Ä™dy

ğŸ“‘ PrzykÅ‚adowy plik CSV
csv
Skopiuj kod
city,location,parameter,value,unit,date
Warsaw,"Warszawa, ul. Wokalna",no2,35.1,Âµg/mÂ³,2025-09-07T19:00:00Z
Warsaw,"Warszawa, ul. Wokalna",o3,9.1,Âµg/mÂ³,2025-09-07T19:00:00Z
New York,Bronx - IS52,o3,0.027,ppm,2025-09-07T19:00:00Z
New York,Queens,pm25,10.3,Âµg/mÂ³,2025-09-07T19:00:00Z
...
ğŸ‘¤ Autor
Projekt przygotowany na potrzeby rekrutacji â€“ Junior Data Engineer (Google Cloud, Python, OpenAQ API).

Autor: Tomasz Welcz
GitHub: tomsongracz
